{
  "142": {
    "inputs": {
      "ckpt_name": "juggernaut_reborn.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -1,
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "positive": "Realistic medium shot photo of a beautiful slim young 28 yo woman with brown long hair, light brown eyes, perfect breast, wearing a tiny bikini, Italian, no makeup, hyperdetailed photography, hard light, cinematic",
      "negative": "embedding:JuggernautNegative-neg.pt hands",
      "token_normalization": "none",
      "weight_interpretation": "comfy",
      "empty_latent_width": 512,
      "empty_latent_height": 768,
      "batch_size": 1,
      "lora_stack": [
        "143",
        0
      ]
    },
    "class_type": "Efficient Loader",
    "_meta": {
      "title": "Efficient Loader"
    }
  },
  "143": {
    "inputs": {
      "input_mode": "simple",
      "lora_count": 2,
      "lora_name_1": "add_detail.safetensors",
      "lora_wt_1": 1,
      "model_str_1": 1,
      "clip_str_1": 1,
      "lora_name_2": "JuggerCineXL2.safetensors",
      "lora_wt_2": 1,
      "model_str_2": 1,
      "clip_str_2": 1,
      "lora_name_3": "None",
      "lora_wt_3": 1,
      "model_str_3": 1,
      "clip_str_3": 1,
      "lora_name_4": "None",
      "lora_wt_4": 1,
      "model_str_4": 1,
      "clip_str_4": 1,
      "lora_name_5": "None",
      "lora_wt_5": 1,
      "model_str_5": 1,
      "clip_str_5": 1,
      "lora_name_6": "None",
      "lora_wt_6": 1,
      "model_str_6": 1,
      "clip_str_6": 1,
      "lora_name_7": "None",
      "lora_wt_7": 1,
      "model_str_7": 1,
      "clip_str_7": 1,
      "lora_name_8": "None",
      "lora_wt_8": 1,
      "model_str_8": 1,
      "clip_str_8": 1,
      "lora_name_9": "None",
      "lora_wt_9": 1,
      "model_str_9": 1,
      "clip_str_9": 1,
      "lora_name_10": "None",
      "lora_wt_10": 1,
      "model_str_10": 1,
      "clip_str_10": 1,
      "lora_name_11": "None",
      "lora_wt_11": 1,
      "model_str_11": 1,
      "clip_str_11": 1,
      "lora_name_12": "None",
      "lora_wt_12": 1,
      "model_str_12": 1,
      "clip_str_12": 1,
      "lora_name_13": "None",
      "lora_wt_13": 1,
      "model_str_13": 1,
      "clip_str_13": 1,
      "lora_name_14": "None",
      "lora_wt_14": 1,
      "model_str_14": 1,
      "clip_str_14": 1,
      "lora_name_15": "None",
      "lora_wt_15": 1,
      "model_str_15": 1,
      "clip_str_15": 1,
      "lora_name_16": "None",
      "lora_wt_16": 1,
      "model_str_16": 1,
      "clip_str_16": 1,
      "lora_name_17": "None",
      "lora_wt_17": 1,
      "model_str_17": 1,
      "clip_str_17": 1,
      "lora_name_18": "None",
      "lora_wt_18": 1,
      "model_str_18": 1,
      "clip_str_18": 1,
      "lora_name_19": "None",
      "lora_wt_19": 1,
      "model_str_19": 1,
      "clip_str_19": 1,
      "lora_name_20": "None",
      "lora_wt_20": 1,
      "model_str_20": 1,
      "clip_str_20": 1,
      "lora_name_21": "None",
      "lora_wt_21": 1,
      "model_str_21": 1,
      "clip_str_21": 1,
      "lora_name_22": "None",
      "lora_wt_22": 1,
      "model_str_22": 1,
      "clip_str_22": 1,
      "lora_name_23": "None",
      "lora_wt_23": 1,
      "model_str_23": 1,
      "clip_str_23": 1,
      "lora_name_24": "None",
      "lora_wt_24": 1,
      "model_str_24": 1,
      "clip_str_24": 1,
      "lora_name_25": "None",
      "lora_wt_25": 1,
      "model_str_25": 1,
      "clip_str_25": 1,
      "lora_name_26": "None",
      "lora_wt_26": 1,
      "model_str_26": 1,
      "clip_str_26": 1,
      "lora_name_27": "None",
      "lora_wt_27": 1,
      "model_str_27": 1,
      "clip_str_27": 1,
      "lora_name_28": "None",
      "lora_wt_28": 1,
      "model_str_28": 1,
      "clip_str_28": 1,
      "lora_name_29": "None",
      "lora_wt_29": 1,
      "model_str_29": 1,
      "clip_str_29": 1,
      "lora_name_30": "None",
      "lora_wt_30": 1,
      "model_str_30": 1,
      "clip_str_30": 1,
      "lora_name_31": "None",
      "lora_wt_31": 1,
      "model_str_31": 1,
      "clip_str_31": 1,
      "lora_name_32": "None",
      "lora_wt_32": 1,
      "model_str_32": 1,
      "clip_str_32": 1,
      "lora_name_33": "None",
      "lora_wt_33": 1,
      "model_str_33": 1,
      "clip_str_33": 1,
      "lora_name_34": "None",
      "lora_wt_34": 1,
      "model_str_34": 1,
      "clip_str_34": 1,
      "lora_name_35": "None",
      "lora_wt_35": 1,
      "model_str_35": 1,
      "clip_str_35": 1,
      "lora_name_36": "None",
      "lora_wt_36": 1,
      "model_str_36": 1,
      "clip_str_36": 1,
      "lora_name_37": "None",
      "lora_wt_37": 1,
      "model_str_37": 1,
      "clip_str_37": 1,
      "lora_name_38": "None",
      "lora_wt_38": 1,
      "model_str_38": 1,
      "clip_str_38": 1,
      "lora_name_39": "None",
      "lora_wt_39": 1,
      "model_str_39": 1,
      "clip_str_39": 1,
      "lora_name_40": "None",
      "lora_wt_40": 1,
      "model_str_40": 1,
      "clip_str_40": 1,
      "lora_name_41": "None",
      "lora_wt_41": 1,
      "model_str_41": 1,
      "clip_str_41": 1,
      "lora_name_42": "None",
      "lora_wt_42": 1,
      "model_str_42": 1,
      "clip_str_42": 1,
      "lora_name_43": "None",
      "lora_wt_43": 1,
      "model_str_43": 1,
      "clip_str_43": 1,
      "lora_name_44": "None",
      "lora_wt_44": 1,
      "model_str_44": 1,
      "clip_str_44": 1,
      "lora_name_45": "None",
      "lora_wt_45": 1,
      "model_str_45": 1,
      "clip_str_45": 1,
      "lora_name_46": "None",
      "lora_wt_46": 1,
      "model_str_46": 1,
      "clip_str_46": 1,
      "lora_name_47": "None",
      "lora_wt_47": 1,
      "model_str_47": 1,
      "clip_str_47": 1,
      "lora_name_48": "None",
      "lora_wt_48": 1,
      "model_str_48": 1,
      "clip_str_48": 1,
      "lora_name_49": "None",
      "lora_wt_49": 1,
      "model_str_49": 1,
      "clip_str_49": 1
    },
    "class_type": "LoRA Stacker",
    "_meta": {
      "title": "LoRA Stacker"
    }
  },
  "149": {
    "inputs": {
      "seed": 8061037385714,
      "steps": 40,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "142",
        0
      ],
      "positive": [
        "204",
        0
      ],
      "negative": [
        "204",
        1
      ],
      "latent_image": [
        "142",
        3
      ],
      "optional_vae": [
        "142",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "151": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.5,
      "samples": [
        "149",
        3
      ]
    },
    "class_type": "LatentUpscaleBy",
    "_meta": {
      "title": "Upscale Latent By"
    }
  },
  "152": {
    "inputs": {
      "seed": 8061037385714,
      "steps": 30,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.55,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "149",
        0
      ],
      "positive": [
        "149",
        1
      ],
      "negative": [
        "246",
        0
      ],
      "latent_image": [
        "151",
        0
      ],
      "optional_vae": [
        "149",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "158": {
    "inputs": {
      "images": [
        "152",
        5
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Latent Upscale 2x"
    }
  },
  "159": {
    "inputs": {
      "images": [
        "149",
        5
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "161": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "162": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "CPU"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "163": {
    "inputs": {
      "guide_size": 384,
      "guide_size_for": true,
      "max_size": 1000,
      "seed": 8061037385714,
      "steps": 35,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.4,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": false,
      "bbox_threshold": 0.4,
      "bbox_dilation": 10,
      "bbox_crop_factor": 2.5,
      "sam_detection_hint": "center-1",
      "sam_dilation": 5,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "image": [
        "152",
        5
      ],
      "model": [
        "142",
        0
      ],
      "clip": [
        "142",
        5
      ],
      "vae": [
        "142",
        4
      ],
      "positive": [
        "219",
        0
      ],
      "negative": [
        "142",
        2
      ],
      "bbox_detector": [
        "161",
        0
      ],
      "sam_model_opt": [
        "162",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "164": {
    "inputs": {
      "control_net_name": "control_v11f1e_sd15_tile.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "165": {
    "inputs": {
      "text": "masterpiece, hyperdetailed, best quality",
      "clip": [
        "142",
        5
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "ControlNet Prompt"
    }
  },
  "166": {
    "inputs": {
      "model_name": "4x_NMKD-Superscale-SP_178000_G.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "167": {
    "inputs": {
      "strength": 1,
      "conditioning": [
        "165",
        0
      ],
      "control_net": [
        "164",
        0
      ],
      "image": [
        "152",
        5
      ]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "168": {
    "inputs": {
      "upscale_by": 1.5,
      "seed": 8061037385714,
      "steps": 25,
      "cfg": 6,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.27,
      "mode_type": "Linear",
      "tile_width": 768,
      "tile_height": 768,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": false,
      "tiled_decode": false,
      "image": [
        "163",
        0
      ],
      "model": [
        "142",
        0
      ],
      "positive": [
        "167",
        0
      ],
      "negative": [
        "142",
        2
      ],
      "vae": [
        "142",
        4
      ],
      "upscale_model": [
        "166",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "169": {
    "inputs": {
      "images": [
        "168",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "203": {
    "inputs": {
      "control_net_name": "controlnet11Models_openpose.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "204": {
    "inputs": {
      "strength": 0.75,
      "start_percent": 0,
      "end_percent": 0.6,
      "positive": [
        "142",
        1
      ],
      "negative": [
        "142",
        2
      ],
      "control_net": [
        "203",
        0
      ],
      "image": [
        "218",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "218": {
    "inputs": {
      "image": "OIP.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "219": {
    "inputs": {
      "text": "beautiful young 28 yo woman with brown long hair, light brown eyes, Italian, no makeup, hyperdetailed, best quality, look down",
      "clip": [
        "142",
        5
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "FaceDetailer Prompt"
    }
  },
  "229": {
    "inputs": {
      "images": [
        "163",
        2
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "246": {
    "inputs": {
      "text": "embedding:JuggernautNegative-neg.pt (nipples:1.2) (bad hands)",
      "clip": [
        "142",
        5
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Upscale Neg"
    }
  },
  "247": {
    "inputs": {
      "version": "SD 1.x",
      "upscale": 1.5,
      "latent": [
        "149",
        3
      ]
    },
    "class_type": "NNLatentUpscale",
    "_meta": {
      "title": "NNLatentUpscale"
    }
  },
  "248": {
    "inputs": {
      "ckpt_name": "juggernaut_reborn.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -1,
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "positive": "Realistic medium shot photo of a beautiful slim young 28 yo woman with brown long hair, light brown eyes, perfect breast, wearing a tiny bikini, Italian, no makeup, hyperdetailed photography, hard light, cinematic",
      "negative": "embedding:JuggernautNegative-neg.pt hands",
      "token_normalization": "none",
      "weight_interpretation": "comfy",
      "empty_latent_width": 512,
      "empty_latent_height": 768,
      "batch_size": 1,
      "lora_stack": [
        "249",
        0
      ]
    },
    "class_type": "Efficient Loader",
    "_meta": {
      "title": "Efficient Loader"
    }
  },
  "249": {
    "inputs": {
      "input_mode": "simple",
      "lora_count": 2,
      "lora_name_1": "add_detail.safetensors",
      "lora_wt_1": 1,
      "model_str_1": 1,
      "clip_str_1": 1,
      "lora_name_2": "JuggerCineXL2.safetensors",
      "lora_wt_2": 1,
      "model_str_2": 1,
      "clip_str_2": 1,
      "lora_name_3": "None",
      "lora_wt_3": 1,
      "model_str_3": 1,
      "clip_str_3": 1,
      "lora_name_4": "None",
      "lora_wt_4": 1,
      "model_str_4": 1,
      "clip_str_4": 1,
      "lora_name_5": "None",
      "lora_wt_5": 1,
      "model_str_5": 1,
      "clip_str_5": 1,
      "lora_name_6": "None",
      "lora_wt_6": 1,
      "model_str_6": 1,
      "clip_str_6": 1,
      "lora_name_7": "None",
      "lora_wt_7": 1,
      "model_str_7": 1,
      "clip_str_7": 1,
      "lora_name_8": "None",
      "lora_wt_8": 1,
      "model_str_8": 1,
      "clip_str_8": 1,
      "lora_name_9": "None",
      "lora_wt_9": 1,
      "model_str_9": 1,
      "clip_str_9": 1,
      "lora_name_10": "None",
      "lora_wt_10": 1,
      "model_str_10": 1,
      "clip_str_10": 1,
      "lora_name_11": "None",
      "lora_wt_11": 1,
      "model_str_11": 1,
      "clip_str_11": 1,
      "lora_name_12": "None",
      "lora_wt_12": 1,
      "model_str_12": 1,
      "clip_str_12": 1,
      "lora_name_13": "None",
      "lora_wt_13": 1,
      "model_str_13": 1,
      "clip_str_13": 1,
      "lora_name_14": "None",
      "lora_wt_14": 1,
      "model_str_14": 1,
      "clip_str_14": 1,
      "lora_name_15": "None",
      "lora_wt_15": 1,
      "model_str_15": 1,
      "clip_str_15": 1,
      "lora_name_16": "None",
      "lora_wt_16": 1,
      "model_str_16": 1,
      "clip_str_16": 1,
      "lora_name_17": "None",
      "lora_wt_17": 1,
      "model_str_17": 1,
      "clip_str_17": 1,
      "lora_name_18": "None",
      "lora_wt_18": 1,
      "model_str_18": 1,
      "clip_str_18": 1,
      "lora_name_19": "None",
      "lora_wt_19": 1,
      "model_str_19": 1,
      "clip_str_19": 1,
      "lora_name_20": "None",
      "lora_wt_20": 1,
      "model_str_20": 1,
      "clip_str_20": 1,
      "lora_name_21": "None",
      "lora_wt_21": 1,
      "model_str_21": 1,
      "clip_str_21": 1,
      "lora_name_22": "None",
      "lora_wt_22": 1,
      "model_str_22": 1,
      "clip_str_22": 1,
      "lora_name_23": "None",
      "lora_wt_23": 1,
      "model_str_23": 1,
      "clip_str_23": 1,
      "lora_name_24": "None",
      "lora_wt_24": 1,
      "model_str_24": 1,
      "clip_str_24": 1,
      "lora_name_25": "None",
      "lora_wt_25": 1,
      "model_str_25": 1,
      "clip_str_25": 1,
      "lora_name_26": "None",
      "lora_wt_26": 1,
      "model_str_26": 1,
      "clip_str_26": 1,
      "lora_name_27": "None",
      "lora_wt_27": 1,
      "model_str_27": 1,
      "clip_str_27": 1,
      "lora_name_28": "None",
      "lora_wt_28": 1,
      "model_str_28": 1,
      "clip_str_28": 1,
      "lora_name_29": "None",
      "lora_wt_29": 1,
      "model_str_29": 1,
      "clip_str_29": 1,
      "lora_name_30": "None",
      "lora_wt_30": 1,
      "model_str_30": 1,
      "clip_str_30": 1,
      "lora_name_31": "None",
      "lora_wt_31": 1,
      "model_str_31": 1,
      "clip_str_31": 1,
      "lora_name_32": "None",
      "lora_wt_32": 1,
      "model_str_32": 1,
      "clip_str_32": 1,
      "lora_name_33": "None",
      "lora_wt_33": 1,
      "model_str_33": 1,
      "clip_str_33": 1,
      "lora_name_34": "None",
      "lora_wt_34": 1,
      "model_str_34": 1,
      "clip_str_34": 1,
      "lora_name_35": "None",
      "lora_wt_35": 1,
      "model_str_35": 1,
      "clip_str_35": 1,
      "lora_name_36": "None",
      "lora_wt_36": 1,
      "model_str_36": 1,
      "clip_str_36": 1,
      "lora_name_37": "None",
      "lora_wt_37": 1,
      "model_str_37": 1,
      "clip_str_37": 1,
      "lora_name_38": "None",
      "lora_wt_38": 1,
      "model_str_38": 1,
      "clip_str_38": 1,
      "lora_name_39": "None",
      "lora_wt_39": 1,
      "model_str_39": 1,
      "clip_str_39": 1,
      "lora_name_40": "None",
      "lora_wt_40": 1,
      "model_str_40": 1,
      "clip_str_40": 1,
      "lora_name_41": "None",
      "lora_wt_41": 1,
      "model_str_41": 1,
      "clip_str_41": 1,
      "lora_name_42": "None",
      "lora_wt_42": 1,
      "model_str_42": 1,
      "clip_str_42": 1,
      "lora_name_43": "None",
      "lora_wt_43": 1,
      "model_str_43": 1,
      "clip_str_43": 1,
      "lora_name_44": "None",
      "lora_wt_44": 1,
      "model_str_44": 1,
      "clip_str_44": 1,
      "lora_name_45": "None",
      "lora_wt_45": 1,
      "model_str_45": 1,
      "clip_str_45": 1,
      "lora_name_46": "None",
      "lora_wt_46": 1,
      "model_str_46": 1,
      "clip_str_46": 1,
      "lora_name_47": "None",
      "lora_wt_47": 1,
      "model_str_47": 1,
      "clip_str_47": 1,
      "lora_name_48": "None",
      "lora_wt_48": 1,
      "model_str_48": 1,
      "clip_str_48": 1,
      "lora_name_49": "None",
      "lora_wt_49": 1,
      "model_str_49": 1,
      "clip_str_49": 1
    },
    "class_type": "LoRA Stacker",
    "_meta": {
      "title": "LoRA Stacker"
    }
  },
  "255": {
    "inputs": {
      "seed": 8061037385714,
      "steps": 40,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "248",
        0
      ],
      "positive": [
        "277",
        0
      ],
      "negative": [
        "277",
        1
      ],
      "latent_image": [
        "248",
        3
      ],
      "optional_vae": [
        "248",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "257": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 1.5,
      "samples": [
        "255",
        3
      ]
    },
    "class_type": "LatentUpscaleBy",
    "_meta": {
      "title": "Upscale Latent By"
    }
  },
  "258": {
    "inputs": {
      "seed": 8061037385714,
      "steps": 30,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.55,
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "255",
        0
      ],
      "positive": [
        "255",
        1
      ],
      "negative": [
        "289",
        0
      ],
      "latent_image": [
        "257",
        0
      ],
      "optional_vae": [
        "255",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "264": {
    "inputs": {
      "images": [
        "258",
        5
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Latent Upscale 2x"
    }
  },
  "265": {
    "inputs": {
      "images": [
        "255",
        5
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "267": {
    "inputs": {
      "model_name": "bbox/face_yolov8m.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "268": {
    "inputs": {
      "model_name": "sam_vit_b_01ec64.pth",
      "device_mode": "CPU"
    },
    "class_type": "SAMLoader",
    "_meta": {
      "title": "SAMLoader (Impact)"
    }
  },
  "269": {
    "inputs": {
      "guide_size": 384,
      "guide_size_for": true,
      "max_size": 1000,
      "seed": 8061037385714,
      "steps": 35,
      "cfg": 5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.4,
      "feather": 5,
      "noise_mask": true,
      "force_inpaint": false,
      "bbox_threshold": 0.4,
      "bbox_dilation": 10,
      "bbox_crop_factor": 2.5,
      "sam_detection_hint": "center-1",
      "sam_dilation": 5,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "image": [
        "258",
        5
      ],
      "model": [
        "248",
        0
      ],
      "clip": [
        "248",
        5
      ],
      "vae": [
        "248",
        4
      ],
      "positive": [
        "279",
        0
      ],
      "negative": [
        "248",
        2
      ],
      "bbox_detector": [
        "267",
        0
      ],
      "sam_model_opt": [
        "268",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "270": {
    "inputs": {
      "control_net_name": "control_v11f1e_sd15_tile.pth"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "271": {
    "inputs": {
      "text": "masterpiece, hyperdetailed, best quality",
      "clip": [
        "248",
        5
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "ControlNet Prompt"
    }
  },
  "272": {
    "inputs": {
      "model_name": "4x_NMKD-Superscale-SP_178000_G.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "273": {
    "inputs": {
      "strength": 1,
      "conditioning": [
        "271",
        0
      ],
      "control_net": [
        "270",
        0
      ],
      "image": [
        "258",
        5
      ]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "274": {
    "inputs": {
      "upscale_by": 1.5,
      "seed": 8061037385714,
      "steps": 25,
      "cfg": 6,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.27,
      "mode_type": "Linear",
      "tile_width": 768,
      "tile_height": 768,
      "mask_blur": 8,
      "tile_padding": 32,
      "seam_fix_mode": "None",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 8,
      "seam_fix_padding": 16,
      "force_uniform_tiles": false,
      "tiled_decode": false,
      "image": [
        "269",
        0
      ],
      "model": [
        "248",
        0
      ],
      "positive": [
        "273",
        0
      ],
      "negative": [
        "248",
        2
      ],
      "vae": [
        "248",
        4
      ],
      "upscale_model": [
        "272",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "275": {
    "inputs": {
      "images": [
        "274",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "276": {
    "inputs": {
      "control_net_name": "controlnet11Models_openpose.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "277": {
    "inputs": {
      "strength": 0.75,
      "start_percent": 0,
      "end_percent": 0.6,
      "positive": [
        "248",
        1
      ],
      "negative": [
        "248",
        2
      ],
      "control_net": [
        "276",
        0
      ],
      "image": [
        "278",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet (Advanced)"
    }
  },
  "278": {
    "inputs": {
      "image": "OIP.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "279": {
    "inputs": {
      "text": "beautiful young 28 yo woman with brown long hair, light brown eyes, Italian, no makeup, hyperdetailed, best quality, look down",
      "clip": [
        "248",
        5
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "FaceDetailer Prompt"
    }
  },
  "285": {
    "inputs": {
      "images": [
        "269",
        2
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "289": {
    "inputs": {
      "text": "embedding:JuggernautNegative-neg.pt (nipples:1.2) (bad hands)",
      "clip": [
        "248",
        5
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Upscale Neg"
    }
  },
  "290": {
    "inputs": {
      "version": "SD 1.x",
      "upscale": 1.5,
      "latent": [
        "255",
        3
      ]
    },
    "class_type": "NNLatentUpscale",
    "_meta": {
      "title": "NNLatentUpscale"
    }
  }
}